{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4556cc",
   "metadata": {},
   "source": [
    "Import libreries that will be useful for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "from tqdm import tqdm  \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30490ca",
   "metadata": {},
   "source": [
    "This block defines the file paths and loads the train.jsonl dataset: initializes an empty train_data list and iterates through the train.jsonl file line by line. Each line is parsed as a separate JSONL object and appended to the train_data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('/kaggle/input', COMPETITION_NAME)\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "train_data = [] \n",
    "\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            train_data.append(json.loads(line))\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db4bb4",
   "metadata": {},
   "source": [
    "Data cleaning phase: the only inconsistency we identified was that not all Pok´emon were at level 100. To ensure uniformity across the dataset, we corrected this issue by retaining only those entries where the Pokemon level was equal to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_battles(data: List[Dict]) -> List[Dict]:\n",
    "    \"\"\" This function is used to only fix the pokemons' level \"\"\"\n",
    "    cleaned_data = []\n",
    "    fixed_count = 0\n",
    "    for battle in data:\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if not isinstance(p1_team, list):\n",
    "            p1_team = []\n",
    "        for pkmn in p1_team:\n",
    "            if pkmn.get('level') != 100:\n",
    "                pkmn['level'] = 100\n",
    "                fixed_count += 1\n",
    "        battle['p1_team_details'] = p1_team\n",
    "        p2_lead = battle.get('p2_lead_details', {})\n",
    "        default_level = 100\n",
    "        if 'level' not in p2_lead or (isinstance(p2_lead.get('level'), (int, float)) and p2_lead['level'] <= 0):\n",
    "            p2_lead['level'] = default_level\n",
    "            fixed_count += 1\n",
    "        battle['p2_lead_details'] = p2_lead\n",
    "        cleaned_data.append(battle)\n",
    "    print(f\"*** Cleaning complete: {len(data)} processed battles, {fixed_count} corrected battles ***\")\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcac8be",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING: This function iterates through each battle's timeline turn-by-turn to aggregate raw statistics (damage, KOs, healing, switches, status turns) for both players.\n",
    "It then engineers a selection of features from these aggregates, focusing on net damage/KO balance, effectiveness, move effect, damage consistency, team diversity, and differences in switches and status ailments, returning them in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152568a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_battle_features(data: list[dict]) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "    for battle in tqdm(data, desc=\"Feature extraction\"): \n",
    "        features = {}\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        timeline = battle.get('battle_timeline', [])\n",
    "        #aggr = dictionary holding total counts and measures like total turns, damage dealt/received\n",
    "        aggr = {'turns':0, 'p1_dmg':0, 'p2_dmg':0, 'p1_ko':0, 'p2_ko':0, 'p2_switch':0, 'p1_heal':0, 'p2_heal':0}\n",
    "        #last_hp = dict that stores the hp percentage of each pokemon at the end of the previous turn\n",
    "        last_hp = {}\n",
    "        #sets that storing the names of the Pokemon belonging to P1 or P2 that have already been KO\n",
    "        ko_p1, ko_p2 = set(), set()\n",
    "        #sets storing the neames of Pok from each team that appeared on the field at any point\n",
    "        p1_pokemon_seen, p2_pokemon_seen = set(), set()\n",
    "        #lists of the total damage delt by each player during each individual turn\n",
    "        p1_damage_by_turn, p2_damage_by_turn = [], []\n",
    "        #lists of the total HP percentage of the active pok for each player at the end of each individual turn\n",
    "        p1_hp_by_turn, p2_hp_by_turn = [], []     \n",
    "        #Count of moves that dealt damage greater than 25%\n",
    "        p1_effective_moves, p2_effective_moves = 0, 0\n",
    "        #Count of moves used by each player that are classified as PHISYCAL OR SPECIAL\n",
    "        p1_total_moves, p2_total_moves = 0, 0\n",
    "        #first_blood = tracks the player who first inflicted significant damage > 15%\n",
    "        first_blood = None   \n",
    "        #ordered list storing which player scored a KO in chronological order\n",
    "        ko_sequence = []\n",
    "        #total number of times each player switched out their active pokemon\n",
    "        p1_switch_count, p2_switch_count = 0, 0\n",
    "        #total turns where a player's active pok was affected by a major status condition (burn, poison)\n",
    "        p1_status_turns, p2_status_turns = 0, 0\n",
    "        #turn number and player who achieved the very first KO of the match\n",
    "        first_ko_turn = None\n",
    "        \n",
    "        for turn_idx, turn in enumerate(timeline):\n",
    "            turn_num = turn_idx + 1\n",
    "            #cumultative damage dealt by both players during this specific turn\n",
    "            p1_dmg_this_turn, p2_dmg_this_turn = 0, 0\n",
    "            #total HP percentage of the active Pokemon for both players\n",
    "            p1_hp_this_turn, p2_hp_this_turn = 0, 0 \n",
    "            for side in ['p1', 'p2']:\n",
    "                state = turn.get(f'{side}_pokemon_state', {})\n",
    "                move = turn.get(f'{side}_move_details')\n",
    "                opp = 'p2' if side == 'p1' else 'p1'\n",
    "                if state:\n",
    "                    poke_name = state.get('name', '')\n",
    "                    cur = state.get('hp_pct', 1.0)\n",
    "                    prev = last_hp.get(f'{side}_{poke_name}', 1.0)\n",
    "                    #calculate damage and healing based on the difference between the precious and current HP values\n",
    "                    dmg = max(prev - cur, 0)\n",
    "                    heal = max(cur - prev, 0)\n",
    "                    if side == 'p1':\n",
    "                        p1_pokemon_seen.add(poke_name)\n",
    "                        #Adds the current HP perentage(cur) to the temporary turn accumulator\n",
    "                        p1_hp_this_turn += cur\n",
    "                    else:\n",
    "                        p2_pokemon_seen.add(poke_name)\n",
    "                        p2_hp_this_turn += cur\n",
    "                    if dmg > 0:\n",
    "                        #accomulate the total raw damage dealt by each player throughout the entire battle\n",
    "                        aggr[f'{opp}_dmg'] += dmg\n",
    "                        #if damage was inflicted by p1\n",
    "                        if opp == 'p1':\n",
    "                            p1_dmg_this_turn += dmg\n",
    "                            if first_blood is None and dmg > 0.15:#only a meaningful attack is counted, ignoring small damage\n",
    "                                first_blood = 'p1'\n",
    "                        else:\n",
    "                            p2_dmg_this_turn += dmg\n",
    "                            if first_blood is None and dmg > 0.15:\n",
    "                                first_blood = 'p2'\n",
    "                    if heal > 0:\n",
    "                        aggr[f'{side}_heal'] += heal\n",
    "                    #check if the player used offensive move\n",
    "                    if move and move.get('category') in ['PHYSICAL', 'SPECIAL']:\n",
    "                        if side == 'p1':\n",
    "                            p1_total_moves += 1\n",
    "                            #if the move caused significant damage it counts as an effective move\n",
    "                            if dmg > 0.25:\n",
    "                                p1_effective_moves += 1\n",
    "                        else:\n",
    "                            p2_total_moves += 1\n",
    "                            if dmg > 0.25:\n",
    "                                p2_effective_moves += 1\n",
    "                    #if the active Pok has a major status condition, the count of tourns spent undeer status for that player is incremented (fnt = svenimento/KO, quando HP pokemon scendono a 0)\n",
    "                    status = state.get('status', 'nostatus')\n",
    "                    if status not in ['nostatus', 'fnt']:\n",
    "                        if side == 'p1':\n",
    "                            p1_status_turns += 1\n",
    "                        else:\n",
    "                            p2_status_turns += 1\n",
    "                    #update the dictionary with the Pok's current HP\n",
    "                    last_hp[f'{side}_{poke_name}'] = cur\n",
    "                    #set the first ko turn and recors which player scored it\n",
    "                    if cur == 0:\n",
    "                        if first_ko_turn is None:\n",
    "                            first_ko_turn = turn_num\n",
    "                        #check if the KO has already been counted; if it's a new one, it will be incremented, add pok's name to the KO set and append the opponent's id to the list ko_sequence\n",
    "                        if side == 'p1' and poke_name not in ko_p2:\n",
    "                            aggr['p2_ko'] += 1\n",
    "                            ko_p2.add(poke_name)\n",
    "                            ko_sequence.append('p2')\n",
    "                        elif side == 'p2' and poke_name not in ko_p1:\n",
    "                            aggr['p1_ko'] += 1\n",
    "                            ko_p1.add(poke_name)\n",
    "                            ko_sequence.append('p1')\n",
    "                #if the player did not use a move, there's a switch\n",
    "                if not move:\n",
    "                    if side == 'p1':\n",
    "                        p1_switch_count += 1\n",
    "                    else:\n",
    "                        p2_switch_count += 1\n",
    "                        aggr['p2_switch'] += 1\n",
    "            #append the temporary pre-turn totals to their respective lists\n",
    "            p1_damage_by_turn.append(p1_dmg_this_turn)\n",
    "            p2_damage_by_turn.append(p2_dmg_this_turn)\n",
    "            p1_hp_by_turn.append(p1_hp_this_turn)\n",
    "            p2_hp_by_turn.append(p2_hp_this_turn)\n",
    "            #increment the total turn\n",
    "            aggr['turns'] += 1\n",
    "        #*----------------------------------------------FEATURES---------------------------------------------------------\n",
    "        for k, v in aggr.items():\n",
    "            features[f'battle_{k}'] = v\n",
    "        features.pop('battle_turns', None)\n",
    "        features.pop('battle_p2_switch', None)\n",
    "        if aggr['turns'] > 0:\n",
    "            #average amount of damage dealt by each players per battle turn\n",
    "            features['p1_dmg_per_turn'] = aggr['p1_dmg'] / aggr['turns']\n",
    "            features['p2_dmg_per_turn'] = aggr['p2_dmg'] / aggr['turns']\n",
    "        #total balance of damage inflicted by P1 compared to damage by P2 over the entire battle; positive value --> P1 inflicted more total dmg than P2 \n",
    "        features['net_balance_damage'] = aggr['p1_dmg'] - aggr['p2_dmg']\n",
    "        #total balance of knocked out Pok achieved by P1 compared to those of P2\n",
    "        features['net_balance_ko'] = aggr['p1_ko'] - aggr['p2_ko']\n",
    "        if len(p1_damage_by_turn) > 1:\n",
    "            #mean damage per turn divided by the StaDev of damae epr turn\n",
    "            p1_dmg_mean = sum(p1_damage_by_turn) / len(p1_damage_by_turn)\n",
    "            p1_dmg_variance = sum((x - p1_dmg_mean)**2 for x in p1_damage_by_turn) / len(p1_damage_by_turn)\n",
    "            features['p1_damage_staDev_consistency'] = p1_dmg_mean / (p1_dmg_variance**0.5 + 0.01)\n",
    "        else:\n",
    "            features['p1_damage_staDev_consistency'] = 0\n",
    "        #divide the count of effective moves (that dealt > 25%) by the total offensive moves used\n",
    "        features['p2_move_effect'] = p2_effective_moves / (p2_total_moves + 1)\n",
    "        #measure diversity of Pok used by P1 relative to the total size of their team\n",
    "        features['p1_team_diversity'] = len(p1_pokemon_seen) / (len(p1_team) + 1)\n",
    "        #measure the absolute number of P2's Pok that were actively brought\n",
    "        features['p2_team_absolute'] = len(p2_pokemon_seen)\n",
    "        #KO streak analysis: analyze the KO sequence to calculate the current consecutive streak for the player who scored the KO. \n",
    "        if len(ko_sequence) > 0:\n",
    "            max_streak_p2 = 0\n",
    "            current_streak = 1\n",
    "            for i in range(1, len(ko_sequence)):\n",
    "                if ko_sequence[i] == ko_sequence[i-1]:\n",
    "                    current_streak += 1\n",
    "                else:\n",
    "                    if ko_sequence[i-1] == 'p2':\n",
    "                        max_streak_p2 = max(max_streak_p2, current_streak)\n",
    "                    current_streak = 1\n",
    "            if ko_sequence[-1] == 'p2':\n",
    "                max_streak_p2 = max(max_streak_p2, current_streak)\n",
    "            #max n of consecutive KOs achieved by each player\n",
    "            features['max_consKo_streak_p2'] = max_streak_p2\n",
    "        else:\n",
    "            features['max_consKo_streak_p2'] = 0\n",
    "        #1 if the first KO was scored by P1\n",
    "        #gap in the total number of times players switched Pok\n",
    "        features['switch_diff_p1_p2'] = p1_switch_count - p2_switch_count\n",
    "        features['p1_afflicted_by_major_status'] = p1_status_turns / (aggr['turns'] + 1)\n",
    "        features['p2_afflicted_by_major_status'] = p2_status_turns / (aggr['turns'] + 1)\n",
    "        features['battle_id'] = battle.get('battle_id')\n",
    "        if 'player_won' in battle:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "        feature_list.append(features)\n",
    "    return pd.DataFrame(feature_list).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c3a2d",
   "metadata": {},
   "source": [
    "This code block loads the test data (test.jsonl). It then applies the clean_battles function to both the training and test datasets.\n",
    "Next, it uses the previously defined create_battle_features function to transform both sets into DataFrames. Finally, it separates the features from the target and splits the training data into training and validation sets to prepare for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCleaning training and test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_data = clean_battles(test_data)\n",
    "\n",
    "train_data = clean_battles(train_data)\n",
    "train_df = create_battle_features(train_data)\n",
    "test_df = create_battle_features(test_data)\n",
    "\n",
    "features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df[features]\n",
    "y = train_df['player_won']\n",
    "X_test = test_df[features]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=True, random_state=42\n",
    ")\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ae28a",
   "metadata": {},
   "source": [
    "This code performs a manual grid search over Logistic Regression hyperparameters, training models with different combinations of C, penalty type, and solver, evaluating their accuracy on a validation set, skipping invalid combinations, and collecting all results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_grid_search_extended(C_value, penalty_type, solver_type):\n",
    "    model = LogisticRegression(C=C_value, penalty=penalty_type, solver=solver_type, max_iter=1000)\n",
    "    predictions = model.fit(X_train, y_train).predict(X_valid)\n",
    "    return [C_value, penalty_type, solver_type, accuracy_score(y_valid, predictions)]\n",
    "\n",
    "results_list = []\n",
    "C_values = [0.01, 0.1, 1, 10]\n",
    "penalty_types = [\"l1\", \"l2\"]\n",
    "solver_types = [\"liblinear\", \"lbfgs\"]\n",
    "\n",
    "for C_value in C_values:\n",
    "    for penalty_type in penalty_types:\n",
    "        for solver_type in solver_types:\n",
    "            try:\n",
    "                results_list.append(logreg_grid_search_extended(C_value, penalty_type, solver_type))\n",
    "            except ValueError:\n",
    "                continue\n",
    "pprint(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea31b6",
   "metadata": {},
   "source": [
    "This code uses GridSearchCV to tune the hyperparameters of a LogisticRegression (in a Pipeline with StandardScaler), optimizing for roc_auc over 5 folds. After finding the best model, it evaluates it on the validation set, runs a 5-fold cross-validation on the full training set (X, y) for accuracy, and finally retrains the model on all data (X, y) to predict on the test set (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489247da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(),  LogisticRegression(max_iter=5000))\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10],\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "print(\"\\n*** Starting GridSearchCV 5-fold ***\")\n",
    "grid_logreg.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_logreg.best_params_\n",
    "best_score = grid_logreg.best_score_\n",
    "\n",
    "print(\"\\n*** Best iperparameters found ***\")\n",
    "print(best_params)\n",
    "print(f\"*** Best ROC-AUC CV: {best_score:.4f} ***\")\n",
    "\n",
    "best_model = grid_logreg.best_estimator_\n",
    "predictions = best_model.predict(X_valid)\n",
    "predictions_proba = best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"\\n*** Performance on validation set ***\")\n",
    "print(\"1. Accuracy:\", round(accuracy_score(y_valid, predictions), 4))\n",
    "print(\"2. ROC-AUC:\", round(roc_auc_score(y_valid, predictions_proba), 4))\n",
    "print(\"3. Confusion Matrix:\\n\", confusion_matrix(y_valid, predictions))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"\\n*** 5-Fold Cross-Validation (accuracy) ***\")\n",
    "print(\"1. Fold scores:\", np.round(cv_scores, 4))\n",
    "print(\"2. Mean:\", np.round(cv_scores.mean(), 4), \"±\", np.round(cv_scores.std(), 4))\n",
    "\n",
    "best_model.fit(X, y)\n",
    "test_predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a93af",
   "metadata": {},
   "source": [
    "This code creates the final submission.csv file, combining the battle_ids from the test set with the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067609e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'],\n",
    "    'player_won': test_predictions\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\n*** File 'submission.csv' built ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227f8f0",
   "metadata": {},
   "source": [
    "This code analyzes the feature importance of the LogisticRegression model using two helper functions. The show_features_importance function first extracts the trained model's coefficients, pairs them with their corresponding feature names, and then creates and prints a DataFrame sorted by absolute importance. The plot_feature_importance function uses this same data to generate a horizontal bar chart. This plot provides a clear visual representation of each feature's impact, using different colors to show the direction of its influence on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_features_importance(model_pipeline, feature_names: list[str]):\n",
    "    logreg = model_pipeline.named_steps['logisticregression']\n",
    "    if not hasattr(logreg, 'coef_'):\n",
    "        print(f\"Error: The model {type(logreg)} does not have the attribute 'coef_'.\")\n",
    "        return\n",
    "    coefficients = logreg.coef_[0]\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': coefficients,\n",
    "        'Importanza_Abs': np.abs(coefficients)\n",
    "    }).sort_values(by='Importanza_Abs', ascending=False)\n",
    "    return importance_df\n",
    "\n",
    "print(f\"\\n*** Total feature: {len(features)} ***\")\n",
    "print(\"*** Standing feature ordered by importance ***\")\n",
    "print(show_features_importance(best_model, features))\n",
    "\n",
    "def plot_feature_importance():\n",
    "    plot_df = show_features_importance(best_model, features) \n",
    "    plot_df['Abs_Coefficient'] = plot_df['Coefficient'].abs()\n",
    "    plot_df = plot_df.sort_values(by='Abs_Coefficient', ascending=True)\n",
    "    colors = ['#C44E52' if c < 0 else '#55A868' for c in plot_df['Coefficient']]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.barh(\n",
    "        plot_df['Feature'], \n",
    "        plot_df['Coefficient'], \n",
    "        color=colors,\n",
    "        edgecolor='none',\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.title(\n",
    "        \"Features' Importance\", \n",
    "        fontsize=18, \n",
    "        fontweight='bold', \n",
    "        color='black'\n",
    "    )\n",
    "    plt.axvline(0, color='gray', linestyle='-', linewidth=0.7)     \n",
    "    plt.xlabel('Coefficient', fontsize=14, color='dimgray')\n",
    "    plt.ylabel(None)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.gca().yaxis.grid(False) \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28afd336",
   "metadata": {},
   "source": [
    "This code defines a function that computes and plots a confusion matrix for given true and predicted labels. It uses seaborn to create a heatmap with annotated counts, custom axis labels for “Loser” and “Winner,” and titles the plot for the validation set, providing a visual summary of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predict 0 (Loser)', 'Predict 1 (Winner)'],\n",
    "                yticklabels=['Real 0 (Loser)', 'Real 1 (Winner)'])\n",
    "    plt.title('Confusion Matrix - Validation Set')\n",
    "    plt.ylabel('Real class')\n",
    "    plt.xlabel('Predict class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887cd38",
   "metadata": {},
   "source": [
    "Plot the confusion matrix for the validation labels and model predictions, compute feature importance dataframe and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe7add",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mclean_battles\u001b[39m(data: \u001b[43mList\u001b[49m[Dict]) -> List[Dict]:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" This function is used to only fix the pokemons' level \"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m     cleaned_data = []\n",
      "\u001b[31mNameError\u001b[39m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(y_valid, predictions)\n",
    "importance_df = show_features_importance(best_model, features)\n",
    "plot_feature_importance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
